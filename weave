#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
import argparse
import subprocess
from pathlib import Path
from scripts import utils, files, config, cache

# ~~~~ sub commands ~~~~
def run(args):
    """
    Main frontend for demultiplexing and QA/QC
    """
    runs = files.get_run_directories(args.rundir, seq_dir=args.seq_dir)
    exec_config = config.base_config(qc=args.noqc)
 
    for (rundir, run_infos) in runs:
        sample_sheet = run_infos['samplesheet']
        sample_list = [
            dict(sid=sample.Sample_ID+'_S'+str(i), r1_adapter=sample.Index, r2_adapter=sample.Index2) 
            for i, sample in enumerate(sample_sheet.samples, start=1)
        ]
        project_list = list(set([_sample.Sample_Project for _sample in sample_sheet.samples]))

        if len(project_list) > 1:
            raise NotImplementedError("Unable to process multiple projects currently.\n" + 
                                      "Please file issue if this message is blocking: https://github.com/OpenOmics/weave/issues")

        pairs = ['1', '2'] if sample_sheet.is_paired_end else ['1']

        # ~~~ general run configuration ~~~
        exec_config['bclconvert'].append(utils.is_bclconvert(sample_sheet))
        exec_config['run_ids'].append(rundir.name)
        exec_config['demux_input_dir'].append(rundir.absolute())
        exec_config['sids'].append([x['sid'] for x in sample_list])
        exec_config['project'].append(project_list[0])
        exec_config['rnums'].append(pairs)

        # ~~~ demultiplexing configuration ~~~
        bcls = [x for x in Path(rundir).rglob('*.bcl.*') if not 'tmp' in str(x)]
        if not bcls:
            bcls = [x for x in Path(rundir).rglob('*.cbcl') if not 'tmp' in str(x)]
        exec_config['bcl_files'].append(bcls)
        exec_config['alreadydemux'].append(False)

        # ~~~ QC/QA configuration ~~~
        sample_sheet = run_infos['samplesheet']
        exec_config['sample_sheet'].append(str(sample_sheet.path.absolute()))
        exec_config['samples'].append(sample_list)
        
        # ~~~ output verification ~~~
        opdir = Path(args.output, rundir.name).absolute() \
            if args.output is not None \
                else Path(Path.cwd(), 'output').absolute()
        files.valid_run_output(opdir, dry_run=args.dry_run)
        exec_config['out_to'].append(opdir)

    utils.exec_pipeline(exec_config, dry_run=args.dry_run, local=args.local)


def get_cache(sub_args):
    """
    Main frontend for cache execution
    """
    skele_config = {k: v if not isinstance(v, list) else "" for k, v in config.base_config(qc=True).items()}
    cache.download(sub_args.cachedir, local=sub_args.local)
    

def unlock_dir(sub_args):
    workflow = config.SNAKEFILE['Illumnia']
    subprocess.Popen(['snakemake', '--unlock'])


# ~~~~ argument parsing commands ~~~~
if __name__ == '__main__':
    main_parser = argparse.ArgumentParser(prog='weave')
    sub_parsers = main_parser.add_subparsers(help='run subcommand help')

    parser_run = sub_parsers.add_parser('run')
    parser_run.add_argument('rundir', metavar='<run directory>', nargs="+", type=utils.valid_run_input, 
                            help='Full & complete run id (format YYMMDD_INSTRUMENTID_TIME_FLOWCELLID) or absolute paths')
    parser_run.add_argument('-s', '--seq_dir', metavar='<sequencing directory>', default=None, type=str,
                            help='Root directory for sequencing data (defaults for biowulf/bigsky/locus), must contain directories ' + \
                            'matching run ids, if not using full paths.')
    parser_run.add_argument('-o', '--output', metavar='<output directory>', default=None, type=str, 
                            help='Top-level output directory for demultiplexing data (defaults to input directory + runid + "_demux")')
    parser_run.add_argument('-d', '--dry-run', action='store_true',
                            help='Dry run the demultiplexing workflow')
    parser_run.add_argument('-n', '--noqc', action='store_false',
                            help='Dry run the demultiplexing workflow')
    parser_run.add_argument('-l', '--local', action='store_true',
                            help='Execute pipeline locally without a dispatching executor')
    # force endedness flags
    endedness = parser_run.add_mutually_exclusive_group()
    endedness.add_argument('--single_end', default=None, action='store_true', 
                            help='Declare endedness of run (in cases in which it is not detectable from sample sheet), mutally exclusive to paired_end')
    endedness.add_argument('--paired_end', default=None, action='store_true',
                           help='Declare endedness of run (in cases in which it is not detectable from sample sheet), mutally exclusive to single_end')

    parser_cache = sub_parsers.add_parser('cache')
    parser_cache.add_argument('cachedir', metavar='<cache directory>', type=cache.valid_dir, 
                            help='Relative or absolute path to directory for cache storage')
    parser_cache.add_argument('-l', '--local', action='store_true',
                            help='Execute pipeline locally without a dispatching executor')
    
    parser_unlock = sub_parsers.add_parser('unlock')
    parser_unlock.add_argument('unlockdir', metavar='<directory to unlock>', type=cache.valid_dir, 
                            help='Relative or absolute path to directory for cache storage')

    parser_run.set_defaults(func = run)
    parser_cache.set_defaults(func = get_cache)
    parser_unlock.set_defaults(func = unlock_dir)
    args = main_parser.parse_args()
    args.func(args)